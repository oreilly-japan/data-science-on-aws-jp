{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 「Data Science」カーネルを起動\n",
    "\n",
    "カーネル上ですべてのノートブックのインタラクションが実行されます。\n",
    "\n",
    "# 画面右上の「No Kernel」をクリック\n",
    "![](img/select_kernel.png)\n",
    "\n",
    "# `Data Science` カーネルを選択\n",
    "![](img/select_data_science_kernel.png)\n",
    "\n",
    "# 画面右上からカーネルが起動したことを確認\n",
    "![](img/confirm_kernel_started.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 注意：　カーネルが起動するまで先に進まないでください\n",
    "# \\#\\#\\# カーネルが起動するまで待機してください！！！ \\#\\#\\#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# セルをひとつひとつ実行するには `Shift+Enter` をタイプ\n",
    "\n",
    "セルを選択して `Shift+Enter` をタイプすると出力が得られます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# すべてのセルを実行するには、`Kernel` をクリック => `Restart Kernel and Run All Cells` を選択\n",
    "![](img/restart-kernel-and-run-all-cells.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ワークショップのイントロダクション\n",
    "\n",
    "このワークショップはオライリージャパンから出版されている「実践 AWSデータサイエンス」に基づいています。\n",
    "\n",
    "[![Data Science on AWS](img/book_full_color_sm.png)](https://www.amazon.com/Data-Science-AWS-End-End/dp/1492079391/)\n",
    "\n",
    "YouTubeビデオ、ミートアップ、本、コードはこちら:  **https://datascienceonaws.com**\n",
    "\n",
    "# ワークショップについて\n",
    "\n",
    "このハンズオンワークショップでは、Amazon SageMakerを使って自然言語処理のためのエンドツーエンドのAI/MLパイプラインを構築します。\n",
    "言語表現の獲得には最先端の[BERT](https://arxiv.org/abs/1810.04805)モデルを使用して、テキストベースの商品レビューを分類するテキスト分類器をトレーニングおよびチューニングします。\n",
    "\n",
    "BERTベースのNLPモデルを構築するために、1995年から2015年までの20年間にAmazon.comに寄せられた1億5千万件以上のカスタマーレビューを含む[Amazon Customer Reviews Dataset](https://s3.amazonaws.com/amazon-reviews-pds/readme.html)を使用します。\n",
    "特に、`review_body`（自由形式のレビューテキスト）から `star_rating` （1が最低、5が最高の星評価）を予測する分類器をトレーニングします。\n",
    "\n",
    "# 学習目標\n",
    "\n",
    "このワークショップでは以下の内容について学びます。\n",
    "\n",
    "* Amazon AthenaとParquetデータフォーマットを使用したS3へのデータの取り込み\n",
    "* SageMakerノートブック上でのpandaやmatplotlibによるデータの可視化\n",
    "* SageMaker Clarifyを使用したデータバイアス分析の実行\n",
    "* Scikit-LearnおよびSageMaker Processing Jobを使用した生データセットに対する特徴量エンジニアリングの実行\n",
    "* SageMaker Feature Storeを使用した特徴量の保存と共有\n",
    "* TensorFlow、Keras、およびSageMaker Training Jobを使用したカスタムBERTモデルのトレーニングと評価\n",
    "* SageMaker Processing Jobを使用したモデルの評価\n",
    "* Amazon SageMaker ML Lineage Trackingを使用したモデルアーティファクトのトラッキング\n",
    "* SageMaker Clarifyを使用したモデルのバイアスおよび説明可能性分析の実行\n",
    "* SageMaker Model Registryを使用したモデルの登録とバージョン管理\n",
    "* SageMaker Endpointを使用したREST推論エンドポイントへのモデルのデプロイ\n",
    "* SageMaker Pipelinesを使用してエンドツーエンドのモデルパイプラインを構築し、MLワークフローのステップを自動化\n",
    "\n",
    "# AmazonのAIおよび機械学習スタック\n",
    "<img src=\"img/aws-ai-ml-stack.png\" width=\"90%\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitterで原著者をフォロー"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "\n",
    "<a href=\"https://twitter.com/cfregly\" class=\"twitter-follow-button\" data-size=\"large\" data-lang=\"en\" data-show-count=\"false\">Follow @cfregly</a>\n",
    "<script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _↑のボタンをクリック_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "\n",
    "<a href=\"https://twitter.com/anbarth\" class=\"twitter-follow-button\" data-size=\"large\" data-lang=\"en\" data-show-count=\"false\">Follow @anbarth</a>\n",
    "<script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _↑のボタンをクリック_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GitHubリポジトリにスターを押す"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "\n",
    "<a class=\"github-button\" href=\"https://github.com/oreilly-japan/data-science-on-aws-jp\" data-color-scheme=\"no-preference: light; light: light; dark: dark;\" data-icon=\"octicon-star\" data-size=\"large\" data-show-count=\"true\" aria-label=\"Star oreilly-japan/data-science-on-aws-jp on GitHub\">Star</a>\n",
    "<script async defer src=\"https://buttons.github.io/buttons.js\"></script>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _↑のボタンをクリック_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science on AWSのウェブサイトにアクセス"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "\n",
    "<iframe src=\"https://datascienceonaws.com\" width=\"800px\" height=\"600px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ユースケース: BERTモデルをファインチューニングし、テキスト分類器を作成\n",
    "\n",
    "メインのデータセットとして [Amazon Customer Reviews Dataset](https://s3.amazonaws.com/amazon-reviews-pds/readme.html) を選択しました。\n",
    "\n",
    "- `marketplace`: 二文字の国コード（今回はすべて「US」）。\n",
    "- `customer_id`: それぞれの書き手のレビュー集約に使われるランダムID。\n",
    "- `review_id`: レビューのユニークID。\n",
    "- `product_id`: Amazon標準識別番号（ASIN）。`http://www.amazon.com/dp/<ASIN>` が商品の詳細ページへのリンクとなる。\n",
    "- `product_parent`: ASINの親。ひとつの親に対して複数のASINが存在しうる（同じ商品の色違いやフォーマット違いなど）。\n",
    "- `product_title`: 商品のタイトル表記。\n",
    "- `product_category`: レビューのグループ化に使う大まかな商品カテゴリー（このケースでは「デジタルビデオ」など）\n",
    "- `star_rating`: レビューの星評価（1〜5）。\n",
    "- `helpful_votes`: レビューへの「役に立った」投票の個数。\n",
    "- `total_votes`: レビューへの全投票数。\n",
    "- `vine`: レビューが[Vine](https://www.amazon.com/gp/vine/help)先取りプログラムの一環で書かれたか否か。\n",
    "- `verified_purchase`: レビューが検証済みの購入に対するものか否か。\n",
    "- `review_headline`: レビューそのもののタイトル。\n",
    "- `review_body`: レビュー本体のテキスト。\n",
    "- `review_date`: レビューが投稿された日付。\n",
    "\n",
    "![BERT Training](img/bert_training.png)\n",
    "\n",
    "BERTのアテンション機構はTransformerと呼ばれています。これは、偶然ではありませんが、[HuggingFace](https://github.com/huggingface/transformers)という会社によってメンテナンスされている、人気のBERT Pythonライブラリ「Transformer」の名前と同じです。今回は、より少ないメモリとコンピューティングパワーで利用できる、[DistilBert](https://arxiv.org/pdf/1910.01108.pdf)と呼ばれるBERTの変種を使用します。軽量ではありながら、今回扱うデータセットでも非常に優れた精度を維持します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERTとSageMaker Pipeline\n",
    "\n",
    "![](./img/bert_sagemaker_pipeline.png)\n",
    "\n",
    "Processingステップでは、事前学習済みBERTモデルを使用して `review_body` テキストからBERT埋め込みを作成するための特徴量エンジニアリングを実行し、データセットをトレーニング、バリデーション、およびテストファイルに分割します。また、Tensorflowのトレーニングに最適化するために、ファイルをTFRecord形式で保存します。\n",
    "\n",
    "Trainingステップでは、BERTモデルをカスタマーレビューデータセットに合わせてファインチューニングし、`review_body` に対する `star_rating` を予測するために新しい分類レイヤーを追加します。\n",
    "\n",
    "Evaluationステップでは、トレーニングされたモデルとテストデータセットを入力とし、分類評価メトリクスを含むJSONファイルを生成します。\n",
    "\n",
    "Conditionステップでは、Evaluationステップで測定されたモデルの精度がある閾値を超えた場合にこのモデルを登録する、という判断を行います。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# リソースの解放"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "\n",
    "<p><b>Shutting down your kernel for this notebook to release resources.</b></p>\n",
    "<button class=\"sm-command-button\" data-commandlinker-command=\"kernelmenu:shutdown\" style=\"display:none;\">Shutdown Kernel</button>\n",
    "\n",
    "<script>\n",
    "try {\n",
    "    els = document.getElementsByClassName(\"sm-command-button\");\n",
    "    els[0].click();\n",
    "}\n",
    "catch(err) {\n",
    "    // NoOp\n",
    "}    \n",
    "</script>"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
